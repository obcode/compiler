% Compiler  
  --- Parsers ---
% Prof. Dr. Oliver Braun
% SS 2014

## Parsing

-   Parsing ist die zweite Stufe im Compiler-Frontend

-   Eingabe ist der Wörterstrom den der Scanner erzeugt

-   der Parser versucht mit Hilfe eines grammatikalischen Models
    eine syntaktische Struktur für das Programm herzuleiten

-   wenn der Parser erkennt, dass die Eingabe ein gültiges Programm ist

    -   erzeugt er ein konkretes Modell des Programms

-   wenn die Eingabe nicht gültig ist, meldet er das Problem und die dazu
    gehörigen diagnostischen Informationen

-   Parsing hat als Problemstellung viele Ähnlichkeiten mit dem Scanning

-   die theoretische Grundlage für Parsertechnologien wurde sehr ausführlich
    als Teilgebiet der formalen Sprachtheorie untersucht

## Syntax

-   wir benötigen eine Notation mit Hilfe derer wir die Syntax einer Sprache
    beschreiben und Programme dagegen prüfen können

-   ein möglicher Kandidat sind reguläre Ausdrücke

-   aber REs sind nicht mächtig genug die komplette Syntax zu beschreiben
    (Beispiel siehe folgende Folie)

-   vielversprechender ist die kontextfreie Grammatik (*context-free grammar (CFG)*)

## Warum keine regulären Ausdrücke?

-   denken wir an das Problem arithmetische Ausdrücke mit Variablen und Operatoren
    zu erkennen

-   der RE $[a...z]([a...z]|[0...9])^* ((+|-|\times|\div)[a...z]([a...z]|[0...9])^* )^*$ 

    -   enthält keinerlei Informationen über den Vorrang von Operatoren,
        z.B. bei $a+b\times c$

-   wir können versuchen Klammern mit zu erkennen:
    $(\backslash(|\epsilon)[a...z]([a...z]|[0...9])^* ((+|-|\times|\div)[a...z]([a...z]|[0...9])^* )^*(\backslash)|\epsilon)$

    -   dieser RE kann ein Klammerpaar um einen Ausdruck erkennen, aber keine
        inneren Klammerpaare

-   nächster Versuch, Klammern im Abschluß:
    $(\backslash(|\epsilon)[a...z]([a...z]|[0...9])^* ((+|-|\times|\div)[a...z]([a...z]|[0...9])^* \backslash)|\epsilon))^*$

    -    aber das würde $a + b) \times c)$ akzeptieren

-   tatsächlich können wir keinen RE schreiben, der alle Ausdrücke mit
    korrekt angeordneten Klammerpaaren erkennen würde und die anderen nicht

## Kontextfreie Grammatik

-   eine kontextfreie Grammatik $G$ ist ein Quadrupel $(T,NT, S, P)$ für das gilt

    -   $T$ ist die Menge von terminalen Symbolen oder Wörtern der Sprache $L(G)$.
        Terminale Symbole entsprechen den syntaktischen Kategorien die der
        Scanner ermittelt.

    -   $NT$ ist die Menge der nichtterminalen Symbolen die in den Produktionsregeln
        von $G$ vorkommen. Nichtterminale Symbole sind syntaktische Variablen.

    -   $S$ ist ein nichtterminales Symbol das als Startsymbol dient.

    -   $P$ ist die Menge von Produktionsreglen von $G$. $P$ hat die Form
        $NT \mapsto (T \cup NT)^+$

## Backus-Naur-Form

-   üblicherweise werden die Produktionsregeln einer CFG in Backus-Naur-Form (BNF)
    angegeben

-   oft genutzt werden:

    -   Extended BNF (EBNF) [[ISO standard](http://www.cl.cam.ac.uk/~mgk25/iso-14977.pdf)]

    -   Augmented BNF (ABNF) [[RFC](http://www.cl.cam.ac.uk/~mgk25/iso-14977.pdf)]

## Beispiele

-   die Sprache der Schafe:

    ------------ --------- ------------------------------------
    *SheepNoise* $\mapsto$ `baa` *SheepNoise*
                 $|$       `baa`
    ------------ --------- ------------------------------------

-   eine Sprache von arithmetischen Ausdrücken mit Klammern

    --- ------ --------- ------------------------------------------
    $1$ *Expr* $\mapsto$ ( *Expr* )
    $2$        $|$       *Expr* *Op* `name`
    $3$        $|$       `name`
    $4$ *Op*   $\mapsto$ +
    $5$        $|$       -
    $6$        $|$       *
    $7$        $|$       /
    --- ------ --------- ------------------------------------------

## Eine Beispiel-Herleitung

-   mit dem Startsymbol *Expr* können wir den Satz $(a+b)*c$ mit einer
    rechtskanonischen Ableitung
    (*rightmost derivation*) herleiten, durch die Sequenz (2,6,1,2,4,3)

    ![Parsebaum von  $(a+b)*c$](img/03/parsetree1.png)

-   die linkskanonische Ableitung (*leftmost derivation*) nutzt die Sequenz
    (2,1,2,3,4,6) und resultiert offensichtlich im selben Parsebaum

## Mehrdeutige Grammatik

-   für einen Compiler ist es wichtig, dass jeder Satz eine eindeutige
    (rechts- oder linkskanonische) Herleitung hat

-   wenn es verschiedene Herleitungen für einen Satz gibt, heißt die Grammatik
    mehrdeutig

-   eine solche Grammatik kann für einen Satz verschiedene Parsebäume erzeugen,
    die potentiell verschiedene Bedeutungen eines Programmes bedeuten können

## Der Klassiker für eine mehrdeutiges Konstrukt

--- ----------- --------- -------------------------------------------------
$1$ *Statement* $\mapsto$ `if` *Expr* `then` *Statement* `else` *Statement*
$2$             $|$       `if` *Expr* `then` *Statement*
$3$             $|$       *Assignment*
$4$             $|$       *...other statements...*
--- ----------- --------- -------------------------------------------------

kann in die beiden Parsebäume resultieren:

![](img/03/parsetree2.png)

![](img/03/parsetree3.png)

## `else` ohne Mehrdeutigkeit

--- ----------- --------- -------------------------------------------------
$1$ *Statement* $\mapsto$ `if` *Expr* `then` *Statement*
$2$             $|$       `if` *Expr* `then` *WithElse* `else` *Statement*
$3$             $|$       *Assignment*
$4$             $|$       *...other statements...*
$5$ *WithElse*  $\mapsto$ `if` *Expr* `then` *WithElse* `else` *WithElse*
$6$             $|$       *Assignment*
--- ----------- --------- -------------------------------------------------

## Bedeutung in Struktur kodieren

-   Parsen von $a+b*c$ resultiert mit den o.a. Regeln in

    ![](img/03/parsetree4.png)

-   ein naheliegender Ansatz den Ausdruck auszuwerten ist den Baum "Postorder"
    zu durchlaufen

-   aber das resultiert in $(a+b)*c$ und nicht $a+b*c$, da wir bislang keinen
    Vorrang der Operatoren in der Grammatik formuliert haben

## Operator Vorrang hinzufügen

--- --------- --------- ----------------------------------
$0$ *Goal*    $\mapsto$ *Expr*
$1$ *Expr*    $\mapsto$ *Expr* + *Term*
$2$           $|$       *Expr* - *Term*
$3$           $|$       *Term*
$4$ *Term*    $\mapsto$ *Term* * *Factor*
$5$           $|$       *Term* / *Factor*
$6$           $|$       *Factor*
$7$ Factor    $\mapsto$ ( *Expr* )
$8$           $|$       `num`
$9$           $|$       `name`
--- --------- --------- ----------------------------------

Durch die Sequenz (0,1,4,6,9,9,3,6,9) bekommen wir jetzt den Parsebaum:

![](img/03/parsetree5.png)

## Top-Down Parsing

-   ein Top-Down Parser beginnt an der Wurzel des Parsebaumes und erweitert ihn
    systematisch nach unten

-   er wählt Nichtterminale am unteren Rand des Baumes aus und erweitert ihn indem
    er Kindknoten hinzufügt die den Regeln entsprechen

-   der Prozess wird solange fortgesetzt bis entweder

    a)  der untere Rand des Baumes nur terminale Symbole enthält **und**
        der Eingabestrom zuende ist, oder
    b)  ein klarer Mismatch zwischen dem unteren Rand und dem Eingabestrom
        entstanden ist.

-   im ersten Fall war der Parser erfolgreich

-   im zweiten Fall

    -   könnte der Parser in einem früheren Schritt eine falsche Regel
        ausgewählt haben. Er kann durch *Backtracking* dort hin zurück und
        mit einer anderen Regel weiter machen

    -   wenn das Backtracking auch nicht zum Erfolg geführt hat, ist die
        Eingabe ungültig

## Top-Down Parsing ...

-   Top-Down Parsing ist für eine große Teilmenge der CFGs, die ohne Backtracking
    auskommt, effizient

-   es gibt Transformationen die *in vielen Fällen* eine beliebige Grammatik
    in eine Grammatik umwandeln kann, die ohne Backtracking aus kommt

-   es gibt zwei verschiedene Ansätze um Top-Down Parser zu bauen:

    1.  Handgeschriebene rekursiv-absteigende Parser
        (*hand-coded recursive-descent parsers*), und

    2.  generierte LL(1) Parser

## Linksrekursion eliminieren

-   eine linkskanonischer Top-Down Parser kann in eine Endlosschleife geraten, wenn
    die Grammatik *Linksrekursion* enthält, z.B.

    ----- --------- --------------
    *Fee* $\mapsto$ *Fee* $\alpha$
          $|$       $\beta$
    ----- --------- --------------

-   diese können wir aber einfach eliminieren durch beispielsweise

    ------ --------- ---------------
    *Fee*  $\mapsto$ $\beta$ *Fee'*
    *Fee'* $\mapsto$ $\alpha$ *Fee'*
           $|$       $\epsilon$
    ------ --------- ---------------

## Aufgabe

Eliminieren Sie die Linksrekursion

--- --------- --------- ----------------------------------
$0$ *Goal*    $\mapsto$ *Expr*
$1$ *Expr*    $\mapsto$ *Expr* + *Term*
$2$           $|$       *Expr* - *Term*
$3$           $|$       *Term*
$4$ *Term*    $\mapsto$ *Term* * *Factor*
$5$           $|$       *Term* / *Factor*
$6$           $|$       *Factor*
$7$ Factor    $\mapsto$ ( *Expr* )
$8$           $|$       `num`
$9$           $|$       `name`
--- --------- --------- ----------------------------------

## Lösung

---- --------- --------- ----------------------------------
 $0$ *Goal*    $\mapsto$ *Expr*
 $1$ *Expr*    $\mapsto$ *Term* *Expr'*
 $2$ *Expr'*   $\mapsto$ + *Term* *Expr'*
 $3$           $|$       - *Term* *Expr'*
 $4$           $|$       $\epsilon$
 $5$ *Term*    $\mapsto$ *Factor* *Term'*
 $6$ *Term'*   $\mapsto$ * *Factor* *Term'*
 $7$           $|$       / *Factor* *Term'*
 $8$           $|$       $\epsilon$
 $9$ *Factor*  $\mapsto$  ( *Expr* )
$10$           $|$       `num`
$11$           $|$       `name`
---- --------- --------- ----------------------------------

## Backtrack-Free Parser

-   das Hauptproblem das zu ineffizientem, linkskanonischem Top-Down Parsen
    führen kann ist Backtracking

-   Backtracking kann vermieden werden, wenn der Parser immer die "richtige"
    Regel auswählt

-   für die vorherige Grammatik, kann der Parser beides, das fokusierte Symbol
    und das nächste Eingabesymbol, in Betracht ziehen, um die nächste Regel
    auszuwählen

-   das nächste Eingabesymbol heißt **lookahead symbol**

-   wir können also sagen, dass eine Grammatik frei von Backtracking ist mit einem
    Symbol lookahead

-   Eine solche Grammatik heißt auch *Predictive Grammar*

## Linksfaktorisierung zum Eliminieren von Backtracking

-   erweitern wir unsere Grammatik durch die folgenden Regeln

    ---- ---------- --------- ------------------------
    $11$ *Factor*   $\mapsto$ `name`
    $12$            $|$       `name` [ *ArgList* ]
    $13$            $|$       `name` ( *ArgList* )
    $15$ *ArgList*  $\mapsto$ *Expr* *MoreArgs*
    $16$ *MoreArgs* $\mapsto$ , *Expr* *MoreArgs*
    $17$            $|$       $\epsilon$ 
    ---- ---------- --------- ------------------------

-   mit einem Lookahead von `name` kann der Parser nicht entscheiden ob er
    Regel 11, 12 oder 13 nehmen soll

-   durch Linksfaktorisierung können wir die Regel ändern in:

    ---- ---------- --------- ------------------------
    $11$ *Factor*    $\mapsto$ `name` *Arguments*
    $12$ *Arguments* $|$       [ *ArgList* ]
    $13$             $|$       ( *ArgList* )
    $14$             $|$       $\epsilon$ 
    ---- ---------- --------- ------------------------

-   Linksfaktorisierung kann in vielen Fällen Backtracking eliminieren

-   es existieren aber kontextfreie Sprachen die keine Backtracking-freie
    Grammatik besitzen

## Top-Down rekursiv-absteigende Parser

-   Backtracking-freie Grammatiken eignen sich zum einfachen und effizienten
    Parsen mit rekursiv-absteigenden Parsern

-   ein rekursiv-absteigender Parser wird durch eine Menge sich gegenseitig
    rekursiv aufrufender Prozeduren, eine für jedes nichtterminale Symbol
    der Grammatik

-   gegeben seien die drei folgenden Regeln:

    ---- --------- --------- ----------------------------------
     $2$ *Expr'*   $\mapsto$ + *Term* *Expr'*
     $3$           $|$       - *Term* *Expr'*
     $4$           $|$       $\epsilon$
    ---- --------- --------- ----------------------------------

-   um Instanzen von *Expr'* zu erkennen, wird eine Prozedur `EPrime()` impelemtiert

    -   die eine Regel gem. dem Lookahead Symbol auswählt

    -   und in Abhängigkeit davon `NextWord()` und die entsprechende Prozedur aufruft

## Table-driven LL(1) Parsers

-   mit Tools können automatisch effiziente Top-Down Parser für Backtracking-freie
    Grammatiken generiert werden

-   die erzeugten Parser heissen LL(1) Parser weil

    -   sie die Eingabe von *l*inks nach rechts verarbeiten,

    -   eine *l*inkskanonische Ableitung konstruieren und

    -   ein Lookahead von **1** Symbol nutzen.

-   Grammatiken die nach einem LL(1)-Schema arbeiten heissen 
    **LL(1) Grammatiken** und sind, per Definition, frei von Backtracking

-   die am meisten verbreitetste Implementierungstechnik nutzt einen
    *table-driven skeleton parser*

## Bottom-Up Parsing

-   Bottom-Up Parser erzeugen den Parsebaum indem sie an den Blättern starten
    und sich nach oben zur Wurzel arbeiten

-   der Parser erzeugt für jedes Wort das der Scanner liefert ein Blatt

-   um eine Ableitung zu erzeugen, fügt der Parser an der oberen Grenze
    eine Schicht von Nichtterminalen über die Blätter

-   der Parser sucht an der oberen Grenze nach einer Zeichenkette die zur rechten
    Seite einer Produktionsregel $A \mapsto \beta$ passt

-   wenn er $\beta$ findet, erzeugt er einen Knoten für $A$ und verbindet die Knoten
    die $\beta$ repräsentieren mit $A$ als Kindknoten

-   das Vorgehen nennen wir **Reduktion**, weil es die Anzahl der Knoten an der
    oberen Grenze reduziert

-   das Ersetzen von $\beta$ durch $A$ an der Position $k$ wird geschrieben
    $\langle A \mapsto \beta, k \rangle$ und heißt ein **Handle**

## Bottom-Up Parsing...

-   der Bottom-Up Parser wiederholt diesen einfachen Prozess

-   er findet ein Handle $\langle A \mapsto \beta, k \rangle$ an der oberen
    Grenze

-   er ersetzt das Vorkommen von $\beta$ bei $k$ mit $A$

-   dieser Prozess wiederholt sich bis entweder

    1.  er die gesamte Grenze zu einem einzigen Knoten ersetzt, der das
        Startsymbol der Grammatik repräsentiert oder

    2.  er kein Handle findet.

-   im ersten Fall hat der Parser eine Herleitung gefunden und, wenn er bereits den
    gesamten Eingabestrom verbraucht hat, ist erfolgreich

-   im zweiten Fall meldet der Parser einen Fehler

-   in vielen Fällen kann der Parser aber trotz Fehler weiter machen
    (error recovery) und so in einem Lauf möglichst viele Fehler finden

TODO: Übersetzen ab hier

## Relationship between derivation and parse

-   the bottom-up parser works from the final sentence toward the goal symbol

-   the derivation starts at the goal symbol and works toward the final sentence

-   the parser discovers the steps of the derivation in reverse order

-   the scanner returns classified words in left-to-right order

-   a bottom-up parser then looks for the rightmost derivation

-   for a derivation:

    $Goal = \gamma_0 \mapsto \gamma_1 \mapsto \gamma_2 \mapsto ... \mapsto \gamma_{n-1} \mapsto \gamma_n = sentence$

    the parser discovers $\gamma_i \mapsto \gamma_{i+1}$ before it discovers
    $\gamma_{i-1} \mapsto \gamma_i$

## LR(1) Parser

-   with an unambiguous grammar, the rightmost derivation is unique

-   for a large class of unambiguous grammars, $\gamma_{i-1}$ can be determined
    directly from $\gamma_i$ and a limited amount of lookahead

-   for such grammars, we can construct an efficient handle-finder, using a technique
    called LR parsing

-   an LR(1) parser scans the input from left to right to build a rightmost derivation
    in reverse

-   the name LR(1) comes from

    -   **L**eft-to-right scan,

    -   **R**everse rightmost derivation, and

    -   **1** symbol of lookahead.

# Practical Parsing Issues

## Error Recovery

-   a parser should find as many syntax errors as possible in each compilation

-   this requires a mechanism that lets the parser recover from an error by moving
    to a state where it can continue parsing

-   a common way is to select one or more words that the parser can use to
    synchronize the input with its internal state

-   when the parser encounters an error, it discards input symbols until it finds
    such a synchronization word

## Finding Semicolons

-   in languages with semicolons as statement separators it calls the scanner
    repeatedly until it finds a semicolon and then changes its state to one that
    would have resulted from successful recognition of a complete statement

-   in a recursive-descent parser, the code can simply discard words until it finds
    a semicolon

-   in an LR(1) parser this is more complex

-   in table-driven parsers the compiler needs a way of telling the parser generator
    where to synchronize

    -   this can be done using error productions --- a production whose right-hand side
        includes a reserved word that indicates a error synchronization point and
        one or more synchronizing tokens

## Unary Operators

-   adding unary operators to the expression grammar requires some care

-   consider adding a unary absolute-value operator $||$ with higher precedence
    than binary operators and lower precedence than parentheses

    ---- --------- --------- ----------------------------------
     $0$ *Goal*    $\mapsto$ *Expr*
     $1$ *Expr*    $\mapsto$ *Expr* + *Term*
     $2$           $|$       *Expr* - *Term*
     $3$           $|$       *Term*
     $4$ *Term*    $\mapsto$ *Term* * *Factor*
     $5$           $|$       *Term* / *Factor*
     $6$           $|$       *Value*
     $7$ *Value*   $\mapsto$ $||$ *Factor*
     $8$           $|$       *Factor*
     $9$ Factor    $\mapsto$ ( *Expr* )
    $10$           $|$       `num`
    $11$           $|$       `name`
    ---- --------- --------- ----------------------------------

-   this grammar does not allow the programmer to write $||\,||x$

## Handling Context-Sensitive Ambiguity

-   using one word to represent different meanings can create a syntactic ambiguity

-   one example arose in several early programming languages, including Fortran, PL/I,
    and Ada

-   these languages used parentheses for both

    -   subscript expressions of an array reference, and

    -   argument lists of subroutines and functions

-   given a textual reference, such as `foo(i,j)`, the compiler cannot tell if
    `foo` is a two-dimensional array or a procedure

-   the scanner undoubtedly classified `foo` as a `name`

## Two different approaches to solve this problem

1.  rewrite the grammar to combine both the function invocation and the array
    reference into a single production

    -   the issue is then deferred until a later step in translation

    -   it can then be resolved with information from declarations

    -   the parser must construct a representation that preserves all information
        needed

    -   the later step will rewrite the reference

2.  the scanner can classify identifiers based on their declared types

    -   requires some hand-shaking between the scanner and the parser

    -   it's not hard as long as the language has a define-before-use rule

    -   the declaration is parsed before the use occurs

    -   the parser can make its internal symbol table available to the scanner
        to resolve identifiers in different classes, such as `variable-name` and
        `function-name`

## Left versus Right Recursion

-   top-down parsers need right recursive grammars, but bottom-up parsers can work
    with both left and right recursive grammars

-   thus, the compiler writer must choose

-   several factors play into this decision

    Stack Depth
    :   in general left recursion can lead to smaller stack depths

    Associativity
    :   left recursion naturally produces left associativity, right recursion right
        associativity

<!-- vim:spell spelllang=de: -->
