% Compiler  
  --- Scanners ---
% Prof. Dr. Oliver Braun
% SS 2014

## Scanner

-   first stage of process to understand the input program
-   scanner = lexical analyzer
-   scanner
    -   reads a stream of characters
    -   produces a stream of words
-   aggregates characters to form words
-   applies a set of rules to determine whether or not the word is valid
-   asign it a syntactic category, if the word is valid

## Recognizing Words --- example

example: recognizing `new`

pseudo code

~~~~
c = nextChar();
if (c == 'n')
    then begin;
        c = nextChar();
        if (c == 'e')
            then begin;
                c = nextChar();
                if (c == 'w')
                    then report success;
                    else try something else;
            end;
            else try something else;
    end;
    else try something else;
~~~~

## Recognizing Words --- example

transition diagram:

![](img/02/FAnew.png)

Haskell:

~~~~ {.haskell}
recognizeNew :: [Char] -> Bool
recognizeNew ('n':'e':'w':_) = True
recognizeNew _               = False
~~~~

## Recognizing different words

![](img/02/FAnewnotwhile.png)

## A Formalism for Recognizers

-   transition diagrams can be viewed as mathematical objects, called **finite automata**

### A finite automaton (FA)

(german: Endlicher Automat (EA))

is a five-tuple $(S, \Sigma, \delta, s_0, S_A)$ where

-   $S$ is the finite set of states in the recognizer, along with an error state $s_e$.
-   $\Sigma$ is the alphabet used by the recognizer. Typically the union of the edge labels in the transition diagram.
-   $\sigma(s,c)$ is the recognizer's transition function. It maps each state $s \in S$ and each character
    $c \in \Sigma$ into some next state.
    In state $s_i$ with input character $c$, the FA takes the transition
    $s_i \stackrel{c}{\mapsto} \sigma(s_i,c)$.
-   $s_0 \in S$ is the designated start state.
-   $S_A$ is the set of accepting states, $S_A \subseteq S$. Each state in $S_A$ appears as a double circle
    in the transition diagram.

## Example

![](img/02/FAnewnotwhile.png)

$S = \{ s_0, s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8, s_9, s_{10}, s_e \}$

$\Sigma = \{ \mathtt{e}, \mathtt{h}, \mathtt{i}, \mathtt{l}, \mathtt{n}, \mathtt{o}, \mathtt{t}, \mathtt{w} \}$

$\sigma = \{ s_0 \stackrel{n}{\mapsto} s_1,
             s_0 \stackrel{w}{\mapsto} s_6, 
             s_1 \stackrel{e}{\mapsto} s_2, ...
          \}$

$s_0 = s_0$

$S_A = \{ s_3, s_5, s_{10} \}$

Exercise: Add the missing mappings to $\sigma$. 

## Example in Haskell

[Clone in FP Haskell Center](https://www.fpcomplete.com/ide?title=FA1&paste=http://ob.cs.hm.edu/docs/lectures/compiler/code/FA1.hs)

[Code](http://ob.cs.hm.edu/docs/lectures/compiler/code/FA1.hs)

## Recognizing positiv Numbers

![](img/02/FAposInt.png)

## Regular Expressions

-   the set of words accepted by a finite automaton, $\cal F$, forms a language, denoted $L(\cal F)$
-   the transition diagram of the FA specifies that language
-   a more intuitive specification is using a notation called a **regular expression** (RE)
-   the language described by an RE is called a **regular language**
-   REs are equivalent to FAs

## Formalizing Regular Expressions

A RE $r$ describes

-   a set of strings, called *language*, denoted $L(r)$
-   over the characters contained in some alphabet $\Sigma$
-   augmented with a character $\epsilon$ that represents the empty string

## Operations

An RE is build up from three basic operations

Alternation
:   The alternation, or union, of two sets of strings $R$ and $S$, denoted $R|S$,
    is $\{ x | x \in R \mbox{ or } x \in S \}$.

Concatenation
:   The concatenation of two sets $R$ and $S$, denoted $RS$, contains all strings
    formed by prepending an element of $R$ onto one from $S$, or
    $\{ xy | x \in R \mbox{ and } y \in S \}$.

Closure
:   The Kleene closure of a set $R$, denoted $R^*$, is $\bigcup^{\infty}_{i=0} R^i$
    This is just the union of the concatenations of $R$ with itself, zero or more times.

For convenience we often use

Finite Closure
:   $R^i$, for some positive $i$

Positive Closure
:   $R^+$ which is just $RR^*$

## Defining Regular Expressions

The set of REs over an alphabet $\Sigma$ is defined as follows

1.  If $a\in\Sigma$, then $a$ is also an RE denoting the set containing only $a$.
2.  If $r$ and $s$ are REs, denoting $L(r)$ and $L(s)$, then
    -   $r|s$ is an RE denoting the union, or alternation, of $L(r)$ and $L(s)$,
    -   $rs$ is an RE denoting the concatenation of $L(r)$ and $L(s)$, and
    -   $r^*$ is an RE denoting the Kleene closure of $L(r)$.
3.  $\epsilon$ is an RE denoting set set containing only the empty string.

## Precedence and Ranges, ...

Order of precendence (from highest):

-   parentheses
-   closure
-   concatenation
-   alternation

Ranges of characters can be specified by the first and the last element connected by an elipsis, "...",
surrounded with a pair of square brackets, e.g., $[0...9]$.

Complement Operator $\^$
:   $\^c$ specifies the set $\Sigma - c$ 

Escape Sequences
:   as in strings, e.g., $\backslash n$

## Examples

-   identifier in some programming languages

    $([A...Z]|[a...z])([A...Z]|[a...z]|[0...9])^*$

-   unsigned int

    $0|[1...9][0...9]^*$

-   unsigned real numbers

    $(0|[1...9][0...9]^*)(\epsilon|.[0...9]^*)$

## Another RE and FA example

-   Java multiline comments RE:

    $/*(\^*|*^+\^/)^**/$

-   Java multiline comments FA:

    ![](img/02/FAjavacomments.png)

# From Regular Expression to Scanner

## Construction Cycle

![](img/02/CycleOfConstructions.png)

## Combining Finite Automata

-   assume we have two FAs:

    ![](img/02/FAn.png) ![](img/02/FAm.png)

-   we can add a transition $\epsilon$ (accepting the empty string) and
    build a FA for $nm$

    ![](img/02/FAnandm.png)

-   we can simply emliminate the $\epsilon$-transition

    ![](img/02/FAnandm2.png)

## Nondeterministic Finite Automata

-   assume we want to merge

    ![](img/02/FAastar.png) ![](img/02/FAab.png)

-   with an $\epsilon$-transition we get

    ![](img/02/FAastarab.png)

    this is an **NFA**, since there are multiple transitions for
    a single character 

## Equivalence of NFAs and DFAs

-   NFAs and DFAs are equivalent in their expression power

-   Any NFA can be simulated by a DFA

-   DFA for $a^*ab$ is

    ![](img/02/DFAastarab.png)

    which is in fact the same as for $aa^*b$

## RE to NFA: Thompson's Construction

-   NFAs for $a$ and $b$

    ![](img/02/NFAa.png) ![](img/02/NFAb.png)

-   NFA für $ab$

    ![](img/02/NFAab.png)

-   NFA für $a | b$

    ![](img/02/NFAaorb.png)

-   NFA für $a^*$

    ![](img/02/NFAastar.png)

## Applying Thompson's Construction

to $a (b | c )^*$

![](img/02/NFAabc.png)

## NFA to DFA: The Subset Construction

-   Subset construction takes an NFA

    $(N, \Sigma, \sigma_N, n_0, N_A)$

    and produces a DFA

    $(D, \Sigma, \sigma_D, d_0, D_A)$

## Subset Construction Algorithm

~~~~
q_0 = epsilonClosure({n_0});
Q = q_0;
Worklist = {q_0};
while (Worklist /= {}) do
    remove q from Worklist;
    for each character c elem Sigma do
        t = epsilonClosure(Delta(q,c));
        T[q,c] = t;
        if t not elem Q then
            add t to Q and to Worklist;
    end;
end;
~~~~

## Example

![Taken from Cooper & Torczon, Engineering a Compiler](img/02/subsetconstr.jpg)

## From Q to D

-   each $q_i \in \mathtt{Q}$ needs a state $d_i \in D$

-   if $q_i$ contains an accepting state of the NFA, then $d_i$ is an accepting state of the DFA

-   $\sigma_D$ can be constructed directly from `T` by observing the mapping from $q_i$ to $d_i$

-   finally the state constructed from $q_0$ becomes $d_0$

## Fixed-Point Computations

-   subset construction is an example of a *fixed-point calculation*

-   a particular style of computation that arises regularly in computer science

-   characterized by the iterated application of a monotone function

-   these computation terminate when they reach a state where further iteration produces
    the same answer, a **fixed-point**

-   fixed-point computations play an important role in compiler construction

## DFA to Minimal DFA: Hopcroft's Algorithm

-   DFA from subset construction can have a large number of states

    -   bigger size of recognizer in memory

-   technique to detect when two states are equivalent

-   Hopcroft's Algorithm constructs a set partition
    $P = \{p_1, p_2, ...p_m\}$ of the DFA states

-   groups together DFA states by their behevior

    if $d_i \stackrel{c}{\mapsto} d_x, d_j \stackrel{c}{\mapsto} d_y$
    and $d_i, d_j \in p_s$, then $d_x$ and $d_y$ must be in the same
    set $p_t$

-   each set $p_s\in P$ should be as large as possible

## Hopcroft's Algorithm

~~~~
T = { D_A, { D - D_A}};
P = {};
while (P /= D) do
    P = T;
    T = {};
    for each set p in P do
        T = T `union` Split(p);
    end;
end;

Split(S) {
    for each c in Sigma do
        if c splits S into s1 and s2
            then return {s1,s2};
    end;
    return S;
}
~~~~

## Example

![Taken from Cooper & Torczon, Engineering a Compiler](img/02/hopcroft.jpg)

## Using a DFA as a Recognizer

-   after turning the minimal DFA into executable code the resulting
    scanner has to return both

    -   the text of the string and
    -   its syntactic category

-   in order to recognize words we can put delimiters, like a blank, between them

-   but this means you have to write `2 + 5` instead of `2+5` 

## Change the notion of acceptance

-   the recognizer should find the longest word that matches one of the REs

-   it should run until it reaches a state $s$ without an outgoing transition on the
    next character

-   if $s$ is an accepting state the scanner should report the word and its category

-   otherwise it should find the most recent accepting state

-   if there is none it should report an error

-   finally there can be several accepting states in the original NFA

    -   e.g. `new` is accepted as keyword and as identifier

    the recognizer must decide which category to return

# Implementing Scanners

## Table-Driven Scanners

-   uses a skeleton scanner for control and

-   a set of generated tables that encode language-specific knowledge

-   the compiler writer provides a set of lexical patterns (REs)

-   the scanner generator produces tables that drive the skeleton scanner

## Example

![Taken from Cooper & Torczon, Engineering a Compiler](img/02/tabledrivenscanner.jpg)

## Avoiding Excess Roll Back

-   consider the RE $ab|(ab)^*c$

-   on the input string $ababababc$ the scanner return the entire string as a single word

-   on the input string $abababab$ it must scan all characters before it can
    determine that the longest prefix is $ab$

    -   then it reads $ababab$ and recognizes $ab$
    -   ...

    ⇒ in the worst case: quadratic time

-   the *maximal munch scanner* avoids this behavior with three differences

    1.  it has a global counter for the position in the input stream
    2.  it has a bit-array for recording dead-end-transitions as the scanner finds
        them
    3.  it has an initialization routine that must be called before each next word.

-   it records specific (state, input position)-pairs that cannot lead to an accepting
    state

## The Maximal Munch Scanner

![Taken from Cooper & Torczon, Engineering a Compiler](img/02/maximalmunchscanner.jpg)

## Direct-Coded Scanners

-   to improve the performance of a table-driven scanner we must reduce
    the cost of

    -   read a character - operation and/or
    -   compute the next DFA transition

-   direct-coded scanners reduce the cost of computing DFA transition by

    -   replacing the explicit representation with an implicit one
    -   and simplifies the two-step, table-lookup computation

## Overhead of table-lookup

-   the table-driven scanner performs two table lookups, one in `CharCat` and
    another in $\sigma$

-   to access the `i`. element of `CharCat`, the code must compute its address
    $@\mathtt{CharCat}_0 + i \times w$

    -   $@\mathtt{CharCat}_0$ is a constant related to the starting address of
        `CharCat` in memory

    -   $w$ is the number of bytes in each element of `CharCat`

-   for $\sigma(state,cat)$ it is
    $@\sigma_0 + (\mathtt{state} \times \mathtt{number of colums in }\sigma + \mathtt{cat}) \times w$

## Replacing the Table-Driven Scanner's While Loop

-   a direct-coded scanner has a specialized code fragment to implement each state

-   it transfers control directly from state-fragment to state-fragment

-   the scanner generator can directly emit this code

-   but the code violates many of the precepts of structured programming

-   since the code is generated, humans should not need to read or debug it

## Example

for $r[0...9]^+$

![Taken from Cooper & Torczon, Engineering a Compiler](img/02/directcodedscanner.jpg)

## Hand-coded scanners

-   generated scanners use a small, constant amount of time per character

-   but many compilers (commercial and open source) use hand-coded scanners 

-   for example, *flex* was build to support the *gcc* project

-   but *gcc 4.0* uses hand-coded scanners in several front ends

-   hand-coded scanners can reduce the overhead of the interfaces between the
    scanner and the rest of the system

-   a careful implementation can improve the mechanisms

    -   to read and
    -   manipulate characters on input

    and the operations

    -   needed to produce a copy of the actual lexeme on output

<!-- vim:spell spelllang=en: -->
