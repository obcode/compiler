% Compiler  
  --- Scanner ---
% Prof. Dr. Oliver Braun
% WS 2014

## Scanner

-   erster Schritt des Prozesses der das Eingabeprogramm verstehen muss
-   Scanner = lexical analyzer
-   ein Scanner
    -   liest eine Zeichen-Strom
    -   produziert einen Strom von Wörtern
-   aggregiert Zeichen um Wörter zu bilden
-   wendet eine Menge von Regeln an um zu entscheiden ob ein Wort akzeptiert wird
    oder nicht
-   weist dem Wort eine syntaktische Kategorie zu, wenn es akzeptiert wurde

## Wörter erkennen --- Beispiel

`new` erkennen

Pseudo Code

~~~~
c = nextChar();
if (c == 'n')
    then begin;
        c = nextChar();
        if (c == 'e')
            then begin;
                c = nextChar();
                if (c == 'w')
                    then report success;
                    else try something else;
            end;
            else try something else;
    end;
    else try something else;
~~~~

## Wörter erkennen --- Beispiel

Zustandsübergangsdiagramm:

![](img/02/FAnew.png)

Haskell:

~~~~ {.haskell}
recognizeNew :: [Char] -> Bool
recognizeNew ('n':'e':'w':_) = True
recognizeNew _               = False
~~~~

## Verschiedene Wörter erkennen

![](img/02/FAnewnotwhile.png)

## Ein Formalismus für Recognizer

-   Zustandsübergangsdiagramme können als mathematische Objekte betrachtet werden,
    sog. **Endliche Automaten** (*finite automata*)

### Ein Endlicher Automat (EA)

(engl. *finite automaton (FA)*)


ist ein Tupel $(S, \Sigma, \delta, s_0, S_A)$ mit

-   $S$ ist die endlichen Menge von Zuständen im EA, sowie ein Fehlerzustand $s_e$.
-   $\Sigma$ ist das vom EA genutzte Alphabet.
    Typischerweise ist es die Vereinigungsmenge der Kantenbezeichnungen im
    Zustandsübergangsdiagramm.
-   $\sigma(s,c)$ ist die Zustandsübergangsfunktion. Es bildet jeden Zustand
    $s \in S$ und jedes Zeichen $c \in \Sigma$ auf den Folgezustand an.
    Im Zustand $s_i$ mit dem Eingabezeichen $c$, nimmt der EA den Übergang
    $s_i \stackrel{c}{\mapsto} \sigma(s_i,c)$.
-   $s_0 \in S$ ist der ausgewählte Startzustand.
-   $S_A$ ist die Menge von akzeptierenden Zuständen, mit
    $S_A \subseteq S$. Jeder Zustand in $S_A$ wird als doppelt umrandeter
    Kreis im Zustandsübergangsdiagramm dargestellt.

## Beispiel

![](img/02/FAnewnotwhile.png)

$S = \{ s_0, s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8, s_9, s_{10}, s_e \}$

$\Sigma = \{ \mathtt{e}, \mathtt{h}, \mathtt{i}, \mathtt{l}, \mathtt{n}, \mathtt{o}, \mathtt{t}, \mathtt{w} \}$

$\sigma = \{ s_0 \stackrel{n}{\mapsto} s_1,
             s_0 \stackrel{w}{\mapsto} s_6, 
             s_1 \stackrel{e}{\mapsto} s_2, ...
          \}$

$s_0 = s_0$

$S_A = \{ s_3, s_5, s_{10} \}$

Übung: Ergänzen Sie $\sigma$ durch die fehlenden Abbildungen. 

## Beispiel in Haskell

[Code auf GitHub](https://github.com/ob-cs-hm-edu/compiler_ea1)

Clonen auf der Kommandozeile mit

    git clone https://github.com/ob-cs-hm-edu/compiler_ea1.git

[Clone in FP Haskell Center](http://www.fpcomplete.com/ide?git=https://github.com/ob-cs-hm-edu/compiler_ea1.git)

## Positive Zahlen erkennen

![](img/02/FAposInt.png)

## Reguläre Ausdrücke

-   die Menge der Wörter die von einem endlichen Automaten $\cal F$ akzeptiert wird,
    bildet eine Sprache, die $L(\cal F)$ bezeichnet wird
-   das Zustandsübergangsdiagramm des EA spezifiziert diese Sprache
-   intuitiver ist die Spezifikation mit **regulären Ausdrücken**
    (*regular expressions (REs)*)
-   die Sprache die durch einen RE beschrieben wird, heisst **reguläre Sprache**
-   REs sind äquivalent zu EAs

## Formalisierung regulärer Ausdrücke

Ein regulärer Ausdruck $r$ beschreibt

-   eine Menge von Zeichenketten, genannt *Sprache*, bezeichnet mit $L(r)$,
-   bestehend aus Zeichen aus einem Alphabet $\Sigma$
-   erweitert um ein Zeichen $\epsilon$ das die leere Zeichenkette repräsentiert

## Operationen

Ein regulärer Ausdruck wird aus drei Grundoperationen zusammengesetzt

Alternative
:   Die Alternative oder Vereinigung von zwei Mengen von Zeichnketten $R$ and $S$,
    wird geschrieben $R|S$ und
    ist $\{ x | x \in R \mbox{ or } x \in S \}$.

Verkettung
:   Die Verkettung zweier Mengen $R$ and $S$, wird geschrieben $RS$ und
    enthält alle Zeichenketten, die entstehend wenn an ein Element aus
    $R$ ein Element aus $S$ angehängt wird, also
    $\{ xy | x \in R \mbox{ and } y \in S \}$.

Kleenesche Hülle
:   Die Kleenesche Hülle, oder Kleene-Stern, einer Menge $R$, wird geschrieben $R^*$
    und ist $\bigcup^{\infty}_{i=0} R^i$.
    Das sind also alle Verkettungen von $R$ mit sich selbst, null bis unendlich mal.

Zusätzlich wird oft genutzt

Endliche Hülle
:   $R^i$, für ein positives $i$

Positive Hülle
:   $R^+$, als Kurzschreibweise für $RR^*$

## Definition regulärer Ausdrücke

Die Menge der REs über einem
Alphabet $\Sigma$ ist definiert durch

1.  Wenn $a\in\Sigma$, dann ist $a$ ein RE der die Menge beschreibt,
    die nur $a$ enthält.
2.  Wenn $r$ und $s$ REs sind die $L(r)$ and $L(s)$ beschreiben, dann gilt:
    -   $r|s$ ist ein RE
    -   $rs$ ist ein RE
    -   $r^*$ ist ein RE
3.  $\epsilon$ ist ein RE der die Menge beschreibt,
    die nur die leere Zeichenkette enthält.

## Vorrang und Intervalle, ...

Reihenfolge des Vorrangs (vom höchsten):

-   Klammern
-   Hülle
-   Verkettung
-   Alternative

Zeichenintervalle können durch das erste und letzte Element verbunden mit drei
Punkten umschloßen von eckigen Klammern beschrieben werden, z.B. $[0...9]$.

Komplementbildungs-Operator $\^$
:   $\^c$ ist die Menge $\Sigma - c$ 

Escape Sequenzen
:   wie in Zeichenketten, z.B. $\backslash n$

## Beispiele

-   Bezeichner in manchen Programmiersprachen

    $([A...Z]|[a...z])([A...Z]|[a...z]|[0...9])^*$

-   positive ganze Zahlen

    $0|[1...9][0...9]^*$

-   positive reelle Zahlen

    $(0|[1...9][0...9]^*)(\epsilon|.[0...9]^*)$

## Ein weiteres RE und EA Beispiel

-   Mehrzeilige Kommentare in Java RE:

    $/*(\^*|*^+\^/)^**/$

-   Mehrzeilige Kommentare in Java EA:

    ![](img/02/FAjavacomments.png)

# Von regulären Ausdrücken zu Scannern

## Konstruktionszyklus

![](img/02/CycleOfConstructions.png)

## Konstruktion von EAs

-   gegeben seien die beiden EAs

    ![](img/02/FAn.png) ![](img/02/FAm.png)

-   Wir können einen $\epsilon$-Übergang, der die leere Zeichenkette akzeptiert,
    einfügen und so einen EA für $nm$ konstruieren.

    ![](img/02/FAnandm.png)

-   Im zweiten Schritt können wir den $\epsilon$-Übergang eliminieren.

    ![](img/02/FAnandm2.png)

## Nichtdeterministischer Endlicher Automat

-   angenommen wir wollen die folgenden beiden EAs konkatenieren

    ![](img/02/FAastar.png) ![](img/02/FAab.png)

-   mit einem $\epsilon$-Übergang bekommen wir

    ![](img/02/FAastarab.png)

    Das ist ein **NEA**, weil es von einem Zustand mehrere Übergänge mit einem
    Zeichen gibt.

## Äquivalenz von NEAs und DEAs

-   NEAs und DEAs sind äquivalent bzgl. ihrer Ausruckskraft

-   jeder NEA kann durch einen DEA simuliert werden

-   DEA für $a^*ab$ ist

    ![](img/02/DFAastarab.png)

    das ist der selbe wie für $aa^*b$

## RE nach NEA: Thompson's Construction

-   NEAs für $a$ und $b$

    ![](img/02/NFAa.png) ![](img/02/NFAb.png)

-   NEA für $ab$

    ![](img/02/NFAab.png)

-   NEA für $a | b$

    ![](img/02/NFAaorb.png)

-   NEA für $a^*$

    ![](img/02/NFAastar.png)

## Anwendung von Thompson's Construction

auf $a (b | c )^*$

![](img/02/NFAabc.png)

## NEA nach DEA: Die Teilmengenkonstruktion

-   die Teilmengenkonstruktion nimmt einen NEA

    $(N, \Sigma, \sigma_N, n_0, N_A)$

    und produziert einen DEA

    $(D, \Sigma, \sigma_D, d_0, D_A)$

## Algorithmus zur Teilmengenkonstruktion

~~~~
q_0 = epsilonClosure({n_0});
Q = q_0;
Worklist = {q_0};
while (Worklist /= {}) do
    remove q from Worklist;
    for each character c elem Sigma do
        t = epsilonClosure(Delta(q,c));
        T[q,c] = t;
        if t not elem Q then
            add t to Q and to Worklist;
    end;
end;
~~~~

## Von Q nach D

-   jedes $q_i \in \mathtt{Q}$ benötigt einen Zustand $d_i \in D$

-   wenn $q_i$ einen akzeptierenden Zustand im NEA enthält, dann ist $d_i$
    ein Endzustand des DEA

-   $\sigma_D$ kann direkt aus `T` konstruiert werden durch die Abbildung von
    $q_i$ nach $d_i$

-   der Zustand der aus $q_0$ konstruiert werden kann, ist $d_0$

## Beispiel

![Aus Cooper & Torczon, Engineering a Compiler](img/02/subsetconstr.jpg)

## FixPunkt-Berechnungen

-   die Teilmengenkonstruktion ist ein Beispiel einer Berechnung eines Fixpunkts

-   diese ist eine Berechnungsart die an vielen Stellen in der Informatik genutzt wird

-   eine monotone Funktion wird wiederholt auf ihr Ergebnis angewendet

-   die Berechnung terminiert wenn sie einen Zustand erreicht bei dem eine weitere
    Iteration das selbe Ergebnis liefert

-   das ist ein Fixpunkt

-   im Compilerbau sind auch häufig Fixpunkt-Berechnung zu finden

## Erzeugen eines minimal DFA aus einem beliebigen DFA: Hopcroft's Algorithmus

-   der mit der Teilmengenkonstruktion hergeleitete DEA kann eine sehr
    große Anzahl von Zuständen haben

    -   damit benötigt ein Scanner viel Speicher

-   Ziel: äquivalente Zustände finden

-   Hopcroft's Algorithmus konstruiert eine Partition
    $P = \{p_1, p_2, ...p_m\}$ der DEA-Zustände

-   gruppiert die Zustände bzgl. des Verhaltens

    wenn $d_i \stackrel{c}{\mapsto} d_x, d_j \stackrel{c}{\mapsto} d_y$
    und $d_i, d_j \in p_s$, dann müssen $d_x$ und $d_y$ in der selben
    Teilmenge $p_t$ sein

    d.h. wir splitten bei Zeichen die von einem Zustand in $p_s$ bleiben und beim
    anderen nicht (nicht kann auch sein, dass es keine Transition für diesen Buchstaben gibt)

-   jede Teilmenge $p_s\in P$ muss maximal groß sein

## Hopcroft's Algorithmus

~~~~
T = { D_A, { D - D_A}};
P = {};
while (P /= D) do
    P = T;
    T = {};
    for each set p in P do
        T = T `union` Split(p);
    end;
end;

Split(S) {
    for each c in Sigma do
        if c splits S into s1 and s2
            then return {s1,s2};
    end;
    return S;
}
~~~~

## Beispiel

![Aus Cooper & Torczon, Engineering a Compiler](img/02/hopcroft.jpg)

## Vom DEA zum Recognizer

-   aus dem minimalen DEA kann der Code für den Recognizer hergeleitet werden

-   der Recognizer muss als Ergebnis liefern

    -   die erkannte Zeichenkette

    -   die syntaktische Kategorie

-   um Wortgrenzen zu erkennen, können wir Trennzeichen, z.B. Leerzeichen,
    zwischen die Wörter schreiben

-   das bedeutet aber, wir müssten `2 + 5` statt `2+5` schreiben

## Eine andere Art zu erkennen

-   der Recognizer muss das längste Wort finden, dass zu einem der regulären
    Ausdrücke passt 

-   er muss solange weiter machen bis er einen Zustand $s$ erreicht von dem
    es keinen Übergang mit dem folgenden Zeichen gibt

-   wenn $s$ ein Endzustand ist, gibt der Scanner das Wort und die syntaktische
    Kategorie zurück

-   sonst muss er den letzten Endzustand finden (backtracking)

-   wenn es keinen gibt ⇒ Fehlermeldung

-   es kann im ursprünglichen NEA mehrere Zustände geben, die passen

    -   z.B. ist `new` ein Schlüsselwort aber auch ein Bezeichner

-   der Scanner muss entscheiden können welche Kategorie er vorzieht


# Implementierung von Scannern

## Table-Driven Scanner

-   nutzt das Gerüst eines Scanners zur Steuerung und

-   eine Menge von generierten Tabellen die das sprachspezifische Wissen enthalten

-   der Compilerbauer muss eine Menge von lexikalischen Mustern (REs) zur Verfügung
    stellen

-   der Scanner-Generator erzeugt die Tabellen

## Example

![Aus Cooper & Torczon, Engineering a Compiler](img/02/tabledrivenscanner.jpg)

## Exzessives Rollback vermeiden

-   gegeben sei der RE $ab|(ab)^*c$

-   für $ababababc$ gibt der Scanner die gesamte Zeichenkette
    als einzelnes Wort zurück

-   für $abababab$ muss der Scanner alle Zeichen lesen bevor er entscheiden kann,
    dass der längste Präfix $ab$ ist

    -   als nächstes liest er $ababab$ und erkennt $ab$
    -   ...

    ⇒ im schlechsten Fall: quaratische Laufzeit

-   der *Maximal Munch Scanner* (*munch* heisst mampfen) vermeidet so ein Verhalten
    avoids durch drei Eigenschaften

    1.  ein globaler Zähler für die Position im Eingabe-Zeichenstrom
    2.  ein Bit-Array um sich Übergänge in "Sackgassen" zum merken
    3.  eine Initialisierungsroutine die vor jedem neuen Wort aufgerufen wird

-   er merkt sich spezifische Paare (Zustand, Position im Eingabestrom) die
    nicht zu einem Zustand des Akzeptierens führen führen können

## Der Maximal Munch Scanner

![Aus Cooper & Torczon, Engineering a Compiler](img/02/maximalmunchscanner.jpg)

## Direct-Coded Scanners

-   Um die Performanz eines Table-Driven Scanners zu verbessen, müssen wir
    die Kosten reduzieren vom

    -   Lesen des nächsten Zeichens

    -   Berechnen des nächsten Zustandübergangs

-   Direct-Coded Scanners reduzieren die Kosten der Berechnung des nächsten
    Zustandübergangs durch

    -   ersetzen der expliziten Repräsentation durch eine implizite

    -   und dadurch Vereinfachung des zweistufigen Tabellenzugriffs

## Overhead des Tabellen-Lookups

-   der Table-Driven Scanner macht zwei Tabellen-Lookups, einer in `CharCat` und
    einer in $\sigma$

-   um das `i`. Element von `CharCat` zu bekommen, muss die Adresse
    $@\mathtt{CharCat}_0 + i \times w$ berechnet werden

    -   $@\mathtt{CharCat}_0$ ist eine Konstante die die Startadresse von
        `CharCat` im Speicher bezeichnet

    -   $w$ ist die Anzahl Bytes von jedem Element in  `CharCat`

-   für $\sigma(state,cat)$ ist es
    $@\sigma_0 + (\mathtt{state} \times \mathtt{number of colums in }\sigma + \mathtt{cat}) \times w$

## Ersatz für die while-Schleife des Table-Driven Scanners

-   ein Direct-Coded Scanner hat für jeden Zustand ein eigenes spezialisiertes
    Codefragment

-   er übergibt die Kontrolle direkt von Zustands-Codefragment zu
    Zustands-Codefragment

-   der Scanner-Generator kann diesen Code direkt erzeugen

-   der Code widerspricht einigen Grundsätzen der strukturierten Programmierung

-   aber nachdem der Code generiert wird, besteht keine Notwendigkeit ihn zu
    lesen oder gar zu debuggen

## Beispiel

erkennt $r[0...9]^+$

![Aus Cooper & Torczon, Engineering a Compiler](img/02/directcodedscanner.jpg)

## Hand-coded Scanner

-   generierte Scanner benötigen eine kurze, konstante Zeitspanne pro Zeichen

-   viele Compiler (kommerzielle und Open Source) benutzen handgeschriebene Scanner

-   z.B. wurde *flex* entwickelt um das *gcc* Projekt zu unterstützen

-   aber *gcc 4.0* nutzt handgeschriebene Scanner in mehreren Frontends

-   handgeschriebene Scanner können den Overhead der Schnittstellen zwischen
    Scanner und dem Rest des Systems reduzieren

-   eine umsichtige Implementierung kann die Mechanismen verbessern, die

    -   Zeichen lesen und
    -   Zeichen manipulieren

    außerdem die Operationen

    -   die benötigt werden um eine Kopie des aktuellen Lexem als Output
        zu erzeugen

<!-- vim:spell spelllang=de: -->
